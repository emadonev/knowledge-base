TAGS: #CNN, #Permanent_note #neural_networks 
LINK: [[CNN architecture]]
SOURCE: [Batch normalization source](https://towardsdatascience.com/batch-normalization-in-3-levels-of-understanding-14c2da90a338)

- A technique used for [[Deep learning networks]] to make them faster and more stable (specifically CNN's)
- Do not use if you are going to use the [[Dropout layer]]!
- Feature between the output layer and the next input layer (between layers) used to stabilize the network
- It is better to use Batch Normalization after the activation function